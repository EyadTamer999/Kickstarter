{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOADING TRANSFORMED DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- main_category: integer (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- deadline: date (nullable = true)\n",
      " |-- launched: date (nullable = true)\n",
      " |-- state: integer (nullable = true)\n",
      " |-- backers: integer (nullable = true)\n",
      " |-- country: integer (nullable = true)\n",
      " |-- usd_pledged_real: integer (nullable = true)\n",
      " |-- usd_goal_real: integer (nullable = true)\n",
      " |-- duration in days: integer (nullable = true)\n",
      "\n",
      "+-------------+--------+----------+----------+-----+-------+-------+----------------+-------------+----------------+\n",
      "|main_category|currency|  deadline|  launched|state|backers|country|usd_pledged_real|usd_goal_real|duration in days|\n",
      "+-------------+--------+----------+----------+-----+-------+-------+----------------+-------------+----------------+\n",
      "|            6|     USD|2012-08-10|2012-07-07|    0|     12|     21|             296|         4000|              34|\n",
      "|            6|     USD|2014-01-05|2013-11-21|    1|    148|     21|           25712|        25000|              45|\n",
      "|           12|     USD|2011-05-16|2011-04-16|    0|      0|     21|               0|          200|              30|\n",
      "|           13|     USD|2015-06-10|2015-05-11|    1|    298|     21|           23447|        10000|              30|\n",
      "|            8|     GBP|2013-11-30|2013-10-31|    1|    122|      9|            7660|         3268|              30|\n",
      "+-------------+--------+----------+----------+-----+-------+-------+----------------+-------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('KickStarter_ML').getOrCreate()\n",
    "df = spark.read.csv('kickstarter_cleaned.csv', header = True, inferSchema = True)\n",
    "df.printSchema()\n",
    "\n",
    "# show features column\n",
    "df.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping our pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericCols = ['main_category','backers','country','usd_pledged_real','usd_goal_real','duration in days']\n",
    "featurizationPipeline = Pipeline(stages = [VectorAssembler(inputCols=numericCols, outputCol=\"feature_vector\")])\n",
    "featurizationPipelineModel = featurizationPipeline.fit(df)\n",
    "df = featurizationPipelineModel.transform(df)\n",
    "train, test = df.randomSplit([0.7, 0.3], seed = 2018)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol = 'feature_vector', labelCol = 'state', maxIter=10)\n",
    "lrModel = lr.fit(train)\n",
    "\n",
    "# Make predictions on the test set.\n",
    "predictions = lrModel.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy = 79.6331976807001 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "true_labels=predictions.select('state')\n",
    "lr_predictions=predictions.select('prediction')\n",
    "\n",
    "accuracy = accuracy_score(true_labels.toPandas(), lr_predictions.toPandas())\n",
    "print(\"Logistic Regression Accuracy =\",accuracy*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt = DecisionTreeClassifier(featuresCol = 'feature_vector', labelCol = 'state', maxDepth = 3)\n",
    "\n",
    "dtModel = dt.fit(train)\n",
    "predictions = dtModel.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy = 92.01840314041849 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "true_labels=predictions.select('state')\n",
    "dt_predictions=predictions.select('prediction')\n",
    "\n",
    "accuracy = accuracy_score(true_labels.toPandas(), dt_predictions.toPandas())\n",
    "print(\"Decision Tree Accuracy =\",accuracy*100,\"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier(featuresCol = 'feature_vector', labelCol = 'state', numTrees=10)\n",
    "rfModel = rf.fit(train)\n",
    "predictions = rfModel.transform(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy = 95.75935462959629 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "true_labels=predictions.select('state')\n",
    "rf_predictions=predictions.select('prediction')\n",
    "\n",
    "accuracy = accuracy_score(true_labels.toPandas(), rf_predictions.toPandas())\n",
    "print(\"Random Forest Accuracy =\",accuracy*100,\"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gbt = GBTClassifier(featuresCol = 'feature_vector', labelCol = 'state', maxIter=10)\n",
    "gbtModel = gbt.fit(train)\n",
    "predictions = gbtModel.transform(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosted Tree Accuracy = 98.02553390715599 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "true_labels=predictions.select('state')\n",
    "gbt_predictions=predictions.select('prediction')\n",
    "\n",
    "accuracy = accuracy_score(true_labels.toPandas(), gbt_predictions.toPandas())\n",
    "print(\"Gradient Boosted Tree Accuracy =\",accuracy*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is understandable why the logistic regression model performed slightly worse than its peers , due the the high number of outliers across our data set , however 79% is considered acceptable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
